{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2224\n",
      "3106\n",
      "536\n",
      "759\n",
      "450"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "load_new.py:53: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  temp[:,j]=np.fft.fft(temp[:,j])\n",
      "load_new.py:85: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  teX=trX[:cut,:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "load_new.py:86: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  teY=trY[:cut]\n",
      "load_new.py:87: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  trX=trX[cut:,:]\n",
      "load_new.py:88: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  trY=trY[cut:]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from load_new import getData\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn import cross_validation\n",
    "import pickle\n",
    "import os.path\n",
    "import scipy\n",
    "import random\n",
    "\n",
    "trX,trY,teX,teY = getData(oh=0)\n",
    "\n",
    "dtrain = xgb.DMatrix(trX, label = trY)\n",
    "dtest = xgb.DMatrix(teX, label = teY)\n",
    "\n",
    "hyperparams_grid = {\n",
    "    'n_round' : 800,\n",
    "    'early_stopping' : 100,\n",
    "    'bst:max_depth' : scipy.stats.randint(10,30),\n",
    "    'bst:eta' : scipy.stats.uniform(0.01,0.2),\n",
    "    'bst:subsample' : scipy.stats.uniform(0.5,0.5),\n",
    "    'bst:colsample_bytree' : scipy.stats.uniform(0.7,0.3)\n",
    "    }\n",
    "hyperparams_grid\n",
    "\n",
    "                            \n",
    "\n",
    "    \n",
    "def draw(v):\n",
    "    if hasattr(v, 'rvs'):\n",
    "        return v.rvs()\n",
    "    elif type(v) is list:\n",
    "        return random.choice(v)\n",
    "    else:\n",
    "        return v\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_hyperparams(hyperparams):\n",
    "    def get_model_results(mdl):\n",
    "            res = {}\n",
    "            res['ntrees'] = mdl.best_iteration+1\n",
    "            res['score'] = mdl.best_score\n",
    "            res['best_ntrees'] = mdl.best_iteration+1\n",
    "            res['best_score'] = mdl.best_score\n",
    "            return res\n",
    "    def get_results_df():\n",
    "        if os.path.isfile('results/results_df_last.pkl'):\n",
    "            return pd.io.pickle.read_pickle('results/results_df_last.pkl')\n",
    "        else:\n",
    "            return pd.DataFrame()\n",
    "\n",
    "    n_round = hyperparams['n_round']\n",
    "    early_stopping = hyperparams['early_stopping']\n",
    "    plst = [\n",
    "            ('bst:max_depth', hyperparams['bst:max_depth']),\n",
    "            ('objective', 'multi:softprob'),\n",
    "            ('silent', 1),\n",
    "            ('bst:eta', hyperparams['bst:eta']),\n",
    "            ('bst:subsample', hyperparams['bst:subsample']),\n",
    "            ('bst:colsample_bytree', hyperparams['bst:colsample_bytree']),\n",
    "            ('num_class', 4),\n",
    "    ]\n",
    "    evallist  = [(dtrain,'train'), (dtest,'test')]\n",
    "    mdl = xgb.train(plst, dtrain, \n",
    "                    num_boost_round = n_round, \n",
    "                    evals = evallist,\n",
    "                    early_stopping_rounds = early_stopping)\n",
    "    line_dict = get_model_results(mdl)\n",
    "    line_dict.update(hyperparams)\n",
    "    line_dict = {k:[v] for k,v in line_dict.iteritems()}\n",
    "    line_df = pd.DataFrame(line_dict)\n",
    "    results_df = get_results_df()\n",
    "    results_df = results_df.append(line_df, ignore_index = True)\n",
    "    results_df.to_pickle('results/results_df_last.pkl')\n",
    "    results_df.to_pickle('results/old/results_df_%s.pkl' % (len(results_df)-1))\n",
    "    file = open(\"results/results_last.txt\", \"w\")\n",
    "    file.write(str(results_df))\n",
    "    file.close()\n",
    "    file = open(\"results/old/results_%s.txt\" % (len(results_df)-1), \"w\")\n",
    "    file.write(str(results_df))\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Will train until test error hasn't decreased in 100 rounds.\n",
      "[0]\ttrain-merror:0.073780\ttest-merror:0.121439\n",
      "[1]\ttrain-merror:0.052066\ttest-merror:0.105091\n",
      "[2]\ttrain-merror:0.040859\ttest-merror:0.103690\n",
      "[3]\ttrain-merror:0.040159\ttest-merror:0.096684\n",
      "[4]\ttrain-merror:0.036657\ttest-merror:0.089211\n",
      "[5]\ttrain-merror:0.035022\ttest-merror:0.086408\n",
      "[6]\ttrain-merror:0.034789\ttest-merror:0.085941\n",
      "[7]\ttrain-merror:0.031520\ttest-merror:0.086875\n",
      "[8]\ttrain-merror:0.028251\ttest-merror:0.085474\n",
      "[9]\ttrain-merror:0.028018\ttest-merror:0.083139\n",
      "[10]\ttrain-merror:0.027784\ttest-merror:0.081738\n",
      "[11]\ttrain-merror:0.027084\ttest-merror:0.082205\n",
      "[12]\ttrain-merror:0.026850\ttest-merror:0.080803\n",
      "[13]\ttrain-merror:0.026850\ttest-merror:0.080336\n",
      "[14]\ttrain-merror:0.024282\ttest-merror:0.080336\n",
      "[15]\ttrain-merror:0.023582\ttest-merror:0.080336\n",
      "[16]\ttrain-merror:0.021947\ttest-merror:0.078001\n",
      "[17]\ttrain-merror:0.021013\ttest-merror:0.076133\n",
      "[18]\ttrain-merror:0.019846\ttest-merror:0.077067\n",
      "[19]\ttrain-merror:0.018912\ttest-merror:0.077534\n",
      "[20]\ttrain-merror:0.017978\ttest-merror:0.074264\n",
      "[21]\ttrain-merror:0.017978\ttest-merror:0.074731\n",
      "[22]\ttrain-merror:0.017044\ttest-merror:0.073330\n",
      "[23]\ttrain-merror:0.016344\ttest-merror:0.073330\n",
      "[24]\ttrain-merror:0.014476\ttest-merror:0.073330\n",
      "[25]\ttrain-merror:0.014009\ttest-merror:0.070995\n",
      "[26]\ttrain-merror:0.013075\ttest-merror:0.070528\n",
      "[27]\ttrain-merror:0.013308\ttest-merror:0.070528\n",
      "[28]\ttrain-merror:0.013075\ttest-merror:0.070061\n",
      "[29]\ttrain-merror:0.011908\ttest-merror:0.067725\n",
      "[30]\ttrain-merror:0.011674\ttest-merror:0.067725\n",
      "[31]\ttrain-merror:0.010273\ttest-merror:0.067725\n",
      "[32]\ttrain-merror:0.009806\ttest-merror:0.069127\n",
      "[33]\ttrain-merror:0.009573\ttest-merror:0.068660\n",
      "[34]\ttrain-merror:0.008639\ttest-merror:0.070061\n",
      "[35]\ttrain-merror:0.008405\ttest-merror:0.070528\n",
      "[36]\ttrain-merror:0.007004\ttest-merror:0.069594\n",
      "[37]\ttrain-merror:0.007004\ttest-merror:0.069127\n",
      "[38]\ttrain-merror:0.006771\ttest-merror:0.067725\n",
      "[39]\ttrain-merror:0.006071\ttest-merror:0.070061\n",
      "[40]\ttrain-merror:0.005370\ttest-merror:0.069127\n",
      "[41]\ttrain-merror:0.005604\ttest-merror:0.067258\n",
      "[42]\ttrain-merror:0.004903\ttest-merror:0.067725\n",
      "[43]\ttrain-merror:0.004670\ttest-merror:0.066791\n",
      "[44]\ttrain-merror:0.004203\ttest-merror:0.066791\n",
      "[45]\ttrain-merror:0.003502\ttest-merror:0.066791\n",
      "[46]\ttrain-merror:0.003269\ttest-merror:0.066791\n",
      "[47]\ttrain-merror:0.002802\ttest-merror:0.065857\n",
      "[48]\ttrain-merror:0.002568\ttest-merror:0.065857\n",
      "[49]\ttrain-merror:0.002802\ttest-merror:0.065390\n",
      "[50]\ttrain-merror:0.002568\ttest-merror:0.064456\n",
      "[51]\ttrain-merror:0.002802\ttest-merror:0.064923\n",
      "[52]\ttrain-merror:0.002335\ttest-merror:0.065390\n",
      "[53]\ttrain-merror:0.002568\ttest-merror:0.064456\n",
      "[54]\ttrain-merror:0.002335\ttest-merror:0.064923\n",
      "[55]\ttrain-merror:0.002101\ttest-merror:0.064456\n",
      "[56]\ttrain-merror:0.001868\ttest-merror:0.064456\n",
      "[57]\ttrain-merror:0.001401\ttest-merror:0.063989\n",
      "[58]\ttrain-merror:0.001167\ttest-merror:0.064456\n",
      "[59]\ttrain-merror:0.001167\ttest-merror:0.064456\n",
      "[60]\ttrain-merror:0.001167\ttest-merror:0.063989\n",
      "[61]\ttrain-merror:0.001167\ttest-merror:0.064456\n",
      "[62]\ttrain-merror:0.001167\ttest-merror:0.064456\n",
      "[63]\ttrain-merror:0.001167\ttest-merror:0.064456\n",
      "[64]\ttrain-merror:0.001167\ttest-merror:0.063522\n",
      "[65]\ttrain-merror:0.000934\ttest-merror:0.063055\n",
      "[66]\ttrain-merror:0.000934\ttest-merror:0.063055\n",
      "[67]\ttrain-merror:0.000934\ttest-merror:0.063522\n",
      "[68]\ttrain-merror:0.000934\ttest-merror:0.063522\n",
      "[69]\ttrain-merror:0.000934\ttest-merror:0.063522\n",
      "[70]\ttrain-merror:0.000934\ttest-merror:0.063055\n",
      "[71]\ttrain-merror:0.000700\ttest-merror:0.063055\n",
      "[72]\ttrain-merror:0.000700\ttest-merror:0.063055\n",
      "[73]\ttrain-merror:0.000700\ttest-merror:0.062588\n",
      "[74]\ttrain-merror:0.000700\ttest-merror:0.063055\n",
      "[75]\ttrain-merror:0.000233\ttest-merror:0.062588\n",
      "[76]\ttrain-merror:0.000233\ttest-merror:0.062588\n",
      "[77]\ttrain-merror:0.000000\ttest-merror:0.062121\n",
      "[78]\ttrain-merror:0.000000\ttest-merror:0.061653\n",
      "[79]\ttrain-merror:0.000000\ttest-merror:0.062121\n",
      "[80]\ttrain-merror:0.000000\ttest-merror:0.063055\n",
      "[81]\ttrain-merror:0.000000\ttest-merror:0.062121\n",
      "[82]\ttrain-merror:0.000000\ttest-merror:0.062588\n",
      "[83]\ttrain-merror:0.000000\ttest-merror:0.062588\n",
      "[84]\ttrain-merror:0.000000\ttest-merror:0.062121\n",
      "[85]\ttrain-merror:0.000000\ttest-merror:0.062588\n",
      "[86]\ttrain-merror:0.000000\ttest-merror:0.062121\n",
      "[87]\ttrain-merror:0.000000\ttest-merror:0.063522\n",
      "[88]\ttrain-merror:0.000000\ttest-merror:0.062121\n",
      "[89]\ttrain-merror:0.000000\ttest-merror:0.062121\n",
      "[90]\ttrain-merror:0.000000\ttest-merror:0.062588\n",
      "[91]\ttrain-merror:0.000000\ttest-merror:0.062121\n",
      "[92]\ttrain-merror:0.000000\ttest-merror:0.061653\n",
      "[93]\ttrain-merror:0.000000\ttest-merror:0.061653\n",
      "[94]\ttrain-merror:0.000000\ttest-merror:0.061186\n",
      "[95]\ttrain-merror:0.000000\ttest-merror:0.060719\n",
      "[96]\ttrain-merror:0.000000\ttest-merror:0.060719\n",
      "[97]\ttrain-merror:0.000000\ttest-merror:0.060719\n",
      "[98]\ttrain-merror:0.000000\ttest-merror:0.060719\n",
      "[99]\ttrain-merror:0.000000\ttest-merror:0.061186\n",
      "[100]\ttrain-merror:0.000000\ttest-merror:0.061186\n",
      "[101]\ttrain-merror:0.000000\ttest-merror:0.060719\n",
      "[102]\ttrain-merror:0.000000\ttest-merror:0.061186\n",
      "[103]\ttrain-merror:0.000000\ttest-merror:0.061186\n",
      "[104]\ttrain-merror:0.000000\ttest-merror:0.060719\n",
      "[105]\ttrain-merror:0.000000\ttest-merror:0.060719\n",
      "[106]\ttrain-merror:0.000000\ttest-merror:0.061653\n",
      "[107]\ttrain-merror:0.000000\ttest-merror:0.061653\n",
      "[108]\ttrain-merror:0.000000\ttest-merror:0.061186\n",
      "[109]\ttrain-merror:0.000000\ttest-merror:0.061653\n",
      "[110]\ttrain-merror:0.000000\ttest-merror:0.061186\n",
      "[111]\ttrain-merror:0.000000\ttest-merror:0.061186\n",
      "[112]\ttrain-merror:0.000000\ttest-merror:0.061186\n",
      "[113]\ttrain-merror:0.000000\ttest-merror:0.061186\n",
      "[114]\ttrain-merror:0.000000\ttest-merror:0.060719\n",
      "[115]\ttrain-merror:0.000000\ttest-merror:0.060719\n",
      "[116]\ttrain-merror:0.000000\ttest-merror:0.060719\n",
      "[117]\ttrain-merror:0.000000\ttest-merror:0.060719\n",
      "[118]\ttrain-merror:0.000000\ttest-merror:0.060719\n",
      "[119]\ttrain-merror:0.000000\ttest-merror:0.060719\n",
      "[120]\ttrain-merror:0.000000\ttest-merror:0.061186\n",
      "[121]\ttrain-merror:0.000000\ttest-merror:0.061653\n",
      "[122]\ttrain-merror:0.000000\ttest-merror:0.061186\n",
      "[123]\ttrain-merror:0.000000\ttest-merror:0.060719\n",
      "[124]\ttrain-merror:0.000000\ttest-merror:0.061186\n",
      "[125]\ttrain-merror:0.000000\ttest-merror:0.061186\n",
      "[126]\ttrain-merror:0.000000\ttest-merror:0.061653\n",
      "[127]\ttrain-merror:0.000000\ttest-merror:0.062588\n",
      "[128]\ttrain-merror:0.000000\ttest-merror:0.061653\n",
      "[129]\ttrain-merror:0.000000\ttest-merror:0.061186\n",
      "[130]\ttrain-merror:0.000000\ttest-merror:0.061653\n",
      "[131]\ttrain-merror:0.000000\ttest-merror:0.061653\n",
      "[132]\ttrain-merror:0.000000\ttest-merror:0.061653\n",
      "[133]\ttrain-merror:0.000000\ttest-merror:0.062121\n",
      "[134]\ttrain-merror:0.000000\ttest-merror:0.061653\n",
      "[135]\ttrain-merror:0.000000\ttest-merror:0.061186\n",
      "[136]\ttrain-merror:0.000000\ttest-merror:0.061186\n",
      "[137]\ttrain-merror:0.000000\ttest-merror:0.061186\n",
      "[138]\ttrain-merror:0.000000\ttest-merror:0.061653\n",
      "[139]\ttrain-merror:0.000000\ttest-merror:0.061653\n",
      "[140]\ttrain-merror:0.000000\ttest-merror:0.061653\n",
      "[141]\ttrain-merror:0.000000\ttest-merror:0.061653\n",
      "[142]\ttrain-merror:0.000000\ttest-merror:0.061653\n",
      "[143]\ttrain-merror:0.000000\ttest-merror:0.061186\n",
      "[144]\ttrain-merror:0.000000\ttest-merror:0.061186\n",
      "[145]\ttrain-merror:0.000000\ttest-merror:0.061186\n",
      "[146]\ttrain-merror:0.000000\ttest-merror:0.061653\n",
      "[147]\ttrain-merror:0.000000\ttest-merror:0.061186\n",
      "[148]\ttrain-merror:0.000000\ttest-merror:0.060719\n",
      "[149]\ttrain-merror:0.000000\ttest-merror:0.060719\n",
      "[150]\ttrain-merror:0.000000\ttest-merror:0.060719\n",
      "[151]\ttrain-merror:0.000000\ttest-merror:0.060719\n",
      "[152]\ttrain-merror:0.000000\ttest-merror:0.060719\n",
      "[153]\ttrain-merror:0.000000\ttest-merror:0.060719\n",
      "[154]\ttrain-merror:0.000000\ttest-merror:0.060252\n",
      "[155]\ttrain-merror:0.000000\ttest-merror:0.060252\n",
      "[156]\ttrain-merror:0.000000\ttest-merror:0.060719\n",
      "[157]\ttrain-merror:0.000000\ttest-merror:0.060719\n",
      "[158]\ttrain-merror:0.000000\ttest-merror:0.060719\n",
      "[159]\ttrain-merror:0.000000\ttest-merror:0.060719\n",
      "[160]\ttrain-merror:0.000000\ttest-merror:0.060252\n",
      "[161]\ttrain-merror:0.000000\ttest-merror:0.060719\n",
      "[162]\ttrain-merror:0.000000\ttest-merror:0.061186\n",
      "[163]\ttrain-merror:0.000000\ttest-merror:0.061186\n",
      "[164]\ttrain-merror:0.000000\ttest-merror:0.060719\n",
      "[165]\ttrain-merror:0.000000\ttest-merror:0.060252\n",
      "[166]\ttrain-merror:0.000000\ttest-merror:0.060252\n",
      "[167]\ttrain-merror:0.000000\ttest-merror:0.060719\n",
      "[168]\ttrain-merror:0.000000\ttest-merror:0.061186\n",
      "[169]\ttrain-merror:0.000000\ttest-merror:0.060719\n",
      "[170]\ttrain-merror:0.000000\ttest-merror:0.061653\n",
      "[171]\ttrain-merror:0.000000\ttest-merror:0.061653\n",
      "[172]\ttrain-merror:0.000000\ttest-merror:0.061653\n",
      "[173]\ttrain-merror:0.000000\ttest-merror:0.061653\n",
      "[174]\ttrain-merror:0.000000\ttest-merror:0.061653\n",
      "[175]\ttrain-merror:0.000000\ttest-merror:0.061653\n",
      "[176]\ttrain-merror:0.000000\ttest-merror:0.061653\n",
      "[177]\ttrain-merror:0.000000\ttest-merror:0.061653\n",
      "[178]\ttrain-merror:0.000000\ttest-merror:0.061653\n",
      "[179]\ttrain-merror:0.000000\ttest-merror:0.061653\n",
      "[180]\ttrain-merror:0.000000\ttest-merror:0.061653\n",
      "[181]\ttrain-merror:0.000000\ttest-merror:0.061653\n",
      "[182]\ttrain-merror:0.000000\ttest-merror:0.061186\n",
      "[183]\ttrain-merror:0.000000\ttest-merror:0.061186\n",
      "[184]\ttrain-merror:0.000000\ttest-merror:0.061653\n",
      "[185]\ttrain-merror:0.000000\ttest-merror:0.061653\n",
      "[186]\ttrain-merror:0.000000\ttest-merror:0.061653\n",
      "[187]\ttrain-merror:0.000000\ttest-merror:0.062121\n",
      "[188]\ttrain-merror:0.000000\ttest-merror:0.061653\n",
      "[189]\ttrain-merror:0.000000\ttest-merror:0.061653\n",
      "[190]\ttrain-merror:0.000000\ttest-merror:0.061653\n",
      "[191]\ttrain-merror:0.000000\ttest-merror:0.062588\n",
      "[192]\ttrain-merror:0.000000\ttest-merror:0.062588\n",
      "[193]\ttrain-merror:0.000000\ttest-merror:0.062588\n",
      "[194]\ttrain-merror:0.000000\ttest-merror:0.062588\n",
      "[195]\ttrain-merror:0.000000\ttest-merror:0.062588\n",
      "[196]\ttrain-merror:0.000000\ttest-merror:0.062588\n",
      "[197]\ttrain-merror:0.000000\ttest-merror:0.062121\n",
      "[198]\ttrain-merror:0.000000\ttest-merror:0.062121\n",
      "[199]\ttrain-merror:0.000000\ttest-merror:0.062121\n",
      "[200]\ttrain-merror:0.000000\ttest-merror:0.062121\n",
      "[201]\ttrain-merror:0.000000\ttest-merror:0.061653\n",
      "[202]\ttrain-merror:0.000000\ttest-merror:0.061653\n",
      "[203]\ttrain-merror:0.000000\ttest-merror:0.061653\n",
      "[204]\ttrain-merror:0.000000\ttest-merror:0.061653\n",
      "[205]\ttrain-merror:0.000000\ttest-merror:0.061186\n",
      "[206]\ttrain-merror:0.000000\ttest-merror:0.060719\n",
      "[207]\ttrain-merror:0.000000\ttest-merror:0.060719\n",
      "[208]\ttrain-merror:0.000000\ttest-merror:0.060719\n",
      "[209]\ttrain-merror:0.000000\ttest-merror:0.061653\n",
      "[210]\ttrain-merror:0.000000\ttest-merror:0.061186\n",
      "[211]\ttrain-merror:0.000000\ttest-merror:0.060719\n",
      "[212]\ttrain-merror:0.000000\ttest-merror:0.060719\n",
      "[213]\ttrain-merror:0.000000\ttest-merror:0.061186\n",
      "[214]\ttrain-merror:0.000000\ttest-merror:0.061653\n",
      "[215]\ttrain-merror:0.000000\ttest-merror:0.061186\n",
      "[216]\ttrain-merror:0.000000\ttest-merror:0.061653\n",
      "[217]\ttrain-merror:0.000000\ttest-merror:0.061653\n",
      "[218]\ttrain-merror:0.000000\ttest-merror:0.061653\n",
      "[219]\ttrain-merror:0.000000\ttest-merror:0.061653\n",
      "[220]\ttrain-merror:0.000000\ttest-merror:0.061653\n",
      "[221]\ttrain-merror:0.000000\ttest-merror:0.061653\n",
      "[222]\ttrain-merror:0.000000\ttest-merror:0.061653\n",
      "[223]\ttrain-merror:0.000000\ttest-merror:0.062121\n",
      "[224]\ttrain-merror:0.000000\ttest-merror:0.061186\n",
      "[225]\ttrain-merror:0.000000\ttest-merror:0.061653\n",
      "[226]\ttrain-merror:0.000000\ttest-merror:0.061186\n",
      "[227]\ttrain-merror:0.000000\ttest-merror:0.061653\n",
      "[228]\ttrain-merror:0.000000\ttest-merror:0.061653\n",
      "[229]\ttrain-merror:0.000000\ttest-merror:0.061653\n",
      "[230]\ttrain-merror:0.000000\ttest-merror:0.061653\n",
      "[231]\ttrain-merror:0.000000\ttest-merror:0.061653\n",
      "[232]\ttrain-merror:0.000000\ttest-merror:0.061653\n",
      "[233]\ttrain-merror:0.000000\ttest-merror:0.061653\n",
      "[234]\ttrain-merror:0.000000\ttest-merror:0.061653\n",
      "[235]\ttrain-merror:0.000000\ttest-merror:0.061653\n",
      "[236]\ttrain-merror:0.000000\ttest-merror:0.062121\n",
      "[237]\ttrain-merror:0.000000\ttest-merror:0.061653\n",
      "[238]\ttrain-merror:0.000000\ttest-merror:0.061653\n",
      "[239]\ttrain-merror:0.000000\ttest-merror:0.062121\n",
      "[240]\ttrain-merror:0.000000\ttest-merror:0.061653\n",
      "[241]\ttrain-merror:0.000000\ttest-merror:0.062121\n",
      "[242]\ttrain-merror:0.000000\ttest-merror:0.061186\n",
      "[243]\ttrain-merror:0.000000\ttest-merror:0.061653\n",
      "[244]\ttrain-merror:0.000000\ttest-merror:0.061653\n",
      "[245]\ttrain-merror:0.000000\ttest-merror:0.061653\n",
      "[246]\ttrain-merror:0.000000\ttest-merror:0.061653\n",
      "[247]\ttrain-merror:0.000000\ttest-merror:0.061653\n",
      "[248]\ttrain-merror:0.000000\ttest-merror:0.061653\n",
      "[249]\ttrain-merror:0.000000\ttest-merror:0.061186\n",
      "[250]\ttrain-merror:0.000000\ttest-merror:0.061186\n",
      "[251]\ttrain-merror:0.000000\ttest-merror:0.061653\n",
      "[252]\ttrain-merror:0.000000\ttest-merror:0.061653\n",
      "[253]\ttrain-merror:0.000000\ttest-merror:0.061653\n",
      "[254]\ttrain-merror:0.000000\ttest-merror:0.061653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "Evaluating hyperparameters\n",
      "0\n",
      "{'bst:colsample_bytree': 0.7939438211106268, 'bst:subsample': 0.5161884514083115, 'bst:max_depth': 12, 'early_stopping': 100, 'n_round': 800, 'bst:eta': 0.1073408314176849}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stopping. Best iteration:\n",
      "[154]\ttrain-merror:0.000000\ttest-merror:0.060252\n",
      "\n"
     ]
    }
   ],
   "source": [
    "N = 1\n",
    "\n",
    "for k in xrange(N):\n",
    "    print '--------------------------'\n",
    "    print 'Evaluating hyperparameters'\n",
    "    print k\n",
    "    hp = {k:draw(v) for k, v in hyperparams_grid.iteritems()}\n",
    "    print hp\n",
    "    evaluate_hyperparams(hp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
