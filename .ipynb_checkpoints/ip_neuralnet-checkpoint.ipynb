{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import theano\n",
    "from theano import tensor as T\n",
    "from theano.sandbox.rng_mrg import MRG_RandomStreams as RandomStreams\n",
    "import numpy as np\n",
    "from load_new import getData\n",
    "import math\n",
    "\n",
    "srng = RandomStreams()\n",
    "\n",
    "def floatX(X):\n",
    "    return np.asarray(X, dtype=theano.config.floatX)\n",
    "\n",
    "def init_weights(shape):\n",
    "    return theano.shared(floatX(np.random.randn(*shape) * 0.01))\n",
    "\n",
    "def rectify(X):\n",
    "    return T.maximum(X, 0.)\n",
    "\n",
    "def softmax(X):\n",
    "    e_x = T.exp(X - X.max(axis=1).dimshuffle(0, 'x'))\n",
    "    return e_x / e_x.sum(axis=1).dimshuffle(0, 'x')\n",
    "\n",
    "def RMSprop(cost, params, lr=0.001, rho=0.9, epsilon=1e-6):\n",
    "    grads = T.grad(cost=cost, wrt=params)\n",
    "    updates = []\n",
    "    for p, g in zip(params, grads):\n",
    "        acc = theano.shared(p.get_value() * 0.)\n",
    "        acc_new = rho * acc + (1 - rho) * g ** 2\n",
    "        gradient_scaling = T.sqrt(acc_new + epsilon)\n",
    "        g = g / gradient_scaling\n",
    "        updates.append((acc, acc_new))\n",
    "        updates.append((p, p - lr * g))\n",
    "    return updates\n",
    "\n",
    "def dropout(X, p=0.):\n",
    "    if p > 0:\n",
    "        retain_prob = 1 - p\n",
    "        X *= srng.binomial(X.shape, p=retain_prob, dtype=theano.config.floatX)\n",
    "        X /= retain_prob\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2224\n",
      "3106\n",
      "536\n",
      "759\n"
     ]
    }
   ],
   "source": [
    "trX,trY,teX,teY=getData(oh=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model(X, w, p_drop_input, p_drop_hidden):\n",
    "    X = dropout(X, p_drop_input)\n",
    "    H={}\n",
    "    h=[]\n",
    "    H[\"h0\"]=X\n",
    "    nbLay=len(w)-1\n",
    "    for i in range(1,nbLay+1):\n",
    "        id=\"h\"+`i`\n",
    "        idp=\"h\"+`i-1`\n",
    "        H[id] = rectify(T.dot(H[idp], w[i-1]))\n",
    "        H[id] = dropout(H[id], p_drop_hidden)\n",
    "        h=np.append(h,H[id])\n",
    "    py_x = softmax(T.dot(H[id], w[i]))\n",
    "    return h, py_x\n",
    "\n",
    "def loss(result,Y):\n",
    "    l=len(Y)\n",
    "    err=0\n",
    "    for i in range(l):\n",
    "        err+=-math.log(result[i,Y[i]])\n",
    "    return err/l\n",
    "\n",
    "def one_hot(x,n):\n",
    "    if type(x) == list:\n",
    "        x = np.array(x)\n",
    "    x = x.flatten().astype(int)\n",
    "    o_h = np.zeros((len(x),n))\n",
    "    o_h[np.arange(len(x)),x] = 1\n",
    "    return o_h\n",
    "\n",
    "def L2_sum(x):\n",
    "    return sum(x.eval().flatten()**2)\n",
    "L2_reg = np.vectorize(L2_sum)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300 3 100 0 0\n",
      "4283\n",
      "10 3 0.749708148494 0.621113440328 0.750583839327\n",
      "0.961685676823 261.537295277 22.6269652546\n",
      "20 3 0.820919915947 0.456888448035 0.817375058384\n",
      "0.427142039222 367.04002392 49.0565166036\n",
      "30 3 0.867849638104 0.349509997249 0.852872489491\n",
      "0.588412575587 410.901951329 73.4137053748\n",
      "40 3 0.890030352557 0.289960283652 0.87202241943\n",
      "0.617462033852 423.288886622 85.3330173215\n",
      "50 3 0.902638337614 0.266288606489 0.875758991126\n",
      "0.545374263771 432.062177293 94.4079544878\n",
      "60 3 0.909409292552 0.250803008019 0.878561419897\n",
      "0.55119096193 442.573689178 101.045786787\n",
      "70 3 0.90637403689 0.253620164397 0.878561419897\n",
      "0.584261020199 445.998177958 105.768305786\n",
      "80 3 0.908241886528 0.246528883999 0.87435777674\n",
      "0.633222736853 452.64828581 108.79101495\n",
      "90 3 0.910109736166 0.238522138148 0.877160205511\n",
      "0.617843539455 451.046754383 112.687784526\n",
      "100 3 0.908241886528 0.245929822587 0.869219990659\n",
      "0.553907867396 451.614674621 115.593436161\n",
      "110 3 0.91127714219 0.235855060834 0.882765063055\n",
      "0.549970082625 452.91816034 118.587733407\n",
      "120 3 0.908708848938 0.236799447779 0.879028491359\n",
      "0.615388450133 457.478664064 121.540194658\n",
      "130 3 0.910109736166 0.2275324806 0.879495562821\n",
      "0.667812946812 458.279580077 124.133601125\n",
      "140 3 0.915246322671 0.226272632762 0.886968706212\n",
      "0.6926642017 457.849686508 125.916439168\n",
      "150 3 0.915946766285 0.210988101639 0.88416627744\n",
      "0.738631923185 453.938284824 127.487421992\n",
      "160 3 0.919682465562 0.216328961962 0.883699205979\n",
      "0.70353555053 450.044579287 128.659666404\n",
      "170 3 0.920616390381 0.211439039415 0.88883699206\n",
      "0.792861098646 442.950332325 128.812489732\n",
      "180 3 0.921783796404 0.211501226178 0.887902849136\n",
      "0.668019848735 441.537932416 129.832668192\n",
      "190 3 0.920849871585 0.21780971992 0.885100420364\n",
      "0.592304495234 442.465444069 131.61731622\n",
      "200 3 0.920149427971 0.224283043546 0.894908921065\n",
      "0.549932511473 443.022446772 133.199020252\n",
      "210 3 0.916880691104 0.230456841813 0.886968706212\n",
      "0.564963121462 441.373852531 133.149238094\n",
      "220 3 0.912211067009 0.235174231618 0.877627276973\n",
      "0.509497018077 437.625479477 132.614789199\n",
      "230 3 0.912911510623 0.242350965177 0.878561419897\n",
      "0.518268869443 436.143205053 132.845791552\n",
      "240 3 0.909876254961 0.239097312052 0.877160205511\n",
      "0.522185890578 441.937821913 134.590938796\n",
      "250 3 0.910343217371 0.24313248606 0.873423633816\n",
      "0.539702330567 442.201836272 135.541403101\n",
      "260 3 0.904973149661 0.263283815374 0.863148061653\n",
      "0.505515681234 437.787655054 134.978976341\n",
      "270 3 0.913144991828 0.232234671669 0.869219990659\n",
      "0.474414720285 437.950516837 134.831536388\n",
      "280 3 0.913378473033 0.235431347378 0.869219990659\n",
      "0.469813439314 433.294802931 134.224689658\n",
      "290 3 0.912444548214 0.233843438508 0.868752919197\n",
      "0.486009322175 433.149853867 133.724258013\n",
      "300 3 0.9215503152 0.211182152736 0.880429705745\n",
      "0.51492885814 431.77239615 133.193622625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<TensorType(float64, matrix)>,\n",
       " <TensorType(float64, matrix)>,\n",
       " <TensorType(float64, matrix)>,\n",
       " <TensorType(float64, matrix)>]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#def neuraln(trX,trY,nb_step=5,nbLay=3,nbNodes=100,p_drop_input=0.2,p_drop_hidden=0.4,lambda2=10000,size_output=4):\n",
    "import random\n",
    "random.seed(1)\n",
    "np.random.seed(1)\n",
    "\n",
    "nb_step=300\n",
    "nbLay=3\n",
    "nbNodes=100\n",
    "p_drop_input=0\n",
    "p_drop_hidden=0\n",
    "lambda2=10000\n",
    "size_input=93\n",
    "size_output=4\n",
    "\n",
    "if 1:   \n",
    "    print nb_step,nbLay,nbNodes,p_drop_input,p_drop_hidden\n",
    "    check=nb_step/10\n",
    "    \n",
    "    params=[init_weights((size_input,nbNodes))]\n",
    "    params.extend([init_weights((nbNodes,nbNodes)) for i in range(nbLay-1)])\n",
    "    params.append(init_weights((nbNodes, size_output)))\n",
    "    \n",
    "    X = T.fmatrix()\n",
    "    Y = T.fmatrix()\n",
    "\n",
    "    noise_h, noise_py_x = model(X,params, p_drop_input, p_drop_hidden)\n",
    "    h, py_x = model(X, params,0,0)\n",
    "    y_x = T.argmax(py_x, axis=1)\n",
    "    \n",
    "    \n",
    "\n",
    "    L1=T.sum([T.sum(abs(params[i])) for i in range(len(params))])\n",
    "\n",
    "    L2 = T.sum([T.sum((params[i])**2) for i in range(len(params))])\n",
    "    \n",
    "    cost = T.mean(T.nnet.categorical_crossentropy(noise_py_x, Y))+0.0001*L1+0.001*L2\n",
    "    \n",
    "    updates = RMSprop(cost, params, lr=0.001)\n",
    "    \n",
    "    train = theano.function(inputs=[X, Y], outputs=cost, updates=updates, allow_input_downcast=True)\n",
    "    predict = theano.function(inputs=[X], outputs=y_x, allow_input_downcast=True)\n",
    "    predictProb=theano.function(inputs=[X], outputs=py_x, allow_input_downcast=True)\n",
    "\n",
    "    print(len(trX))\n",
    "    i=0\n",
    "    while i<nb_step:\n",
    "        i+=1\n",
    "        for start, end in zip(range(0, len(trX), 10), range(10, len(trX), 10)):\n",
    "            cost = train(trX[start:end], trY[start:end])\n",
    "        #cost=train(trX,trY)\n",
    "        scoreTr=np.mean(np.argmax(trY, axis=1) == predict(trX))\n",
    "        \n",
    "        if i%10==0:#(nb_step/1)==0:\n",
    "            result=predictProb(trX)\n",
    "            argY=np.argmax(trY, axis=1)\n",
    "            logTr=loss(result,argY)\n",
    "            print i,nbLay,scoreTr,logTr, np.mean(np.argmax(teY, axis=1) == predict(teX))\n",
    "            print cost,0.0001*L1.eval(),0.001*L2.eval()\n",
    "\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 3 0.929021713752 0.189983357288 0.880429705745\n",
      "0.53552300623 0.0426072876102 0.132001358373\n",
      "20 3 0.929255194957 0.190375314442 0.879962634283\n",
      "0.581625875113 0.0422055179308 0.130858573011\n",
      "30 3 0.920382909176 0.213887109812 0.880429705745\n",
      "0.617730668896 0.0418121430044 0.130455378825\n",
      "40 3 0.919915946766 0.209644271054 0.875291919664\n",
      "0.61533920482 0.0417405470809 0.130467886419\n",
      "50 3 0.929488676162 0.19710415419 0.877627276973\n",
      "0.603230618393 0.0416962118081 0.131067061212\n",
      "60 3 0.922484240019 0.197055511259 0.878094348435\n",
      "0.666728819961 0.0415854505629 0.131067499345\n",
      "70 3 0.92598645809 0.202003314094 0.879962634283\n",
      "0.624741431786 0.0418492837756 0.132223829614\n",
      "80 3 0.925286014476 0.199647849402 0.880896777207\n",
      "0.608079573738 0.0419239357775 0.133604083802\n",
      "90 3 0.925519495681 0.194385417111 0.875758991126\n",
      "0.655864897712 0.0415647763033 0.134706476557\n",
      "100 3 0.92598645809 0.207991516082 0.875758991126\n",
      "0.675580555092 0.0416251050576 0.136006757785\n",
      "110 3 0.922951202428 0.217538295677 0.870154133582\n",
      "0.701865006662 0.0413781287385 0.135698567138\n",
      "120 3 0.914545879057 0.237068113001 0.858477347034\n",
      "0.66399132892 0.0415170167786 0.135982646925\n",
      "130 3 0.920149427971 0.225065059692 0.863148061653\n",
      "0.725547865962 0.0416097460077 0.136313125537\n",
      "140 3 0.925286014476 0.214070660448 0.861279775806\n",
      "0.673824316599 0.0416975952059 0.136730478691\n",
      "150 3 0.917347653514 0.224532172024 0.86221391873\n",
      "0.591579216592 0.0417822148039 0.137183974928\n",
      "160 3 0.922484240019 0.216596900422 0.867818776273\n",
      "0.581652845602 0.0419433295482 0.138365672315\n",
      "170 3 0.927854307728 0.197522771354 0.87202241943\n",
      "0.609442859318 0.0419215639043 0.138889217341\n",
      "180 3 0.921316833995 0.208864842604 0.863148061653\n",
      "0.564926121484 0.0419182254746 0.13866387197\n",
      "190 3 0.918748540742 0.221391906602 0.864082204577\n",
      "0.587139139191 0.0418074427152 0.138668695416\n",
      "200 3 0.918281578333 0.219243866218 0.87669313405\n",
      "0.488828287901 0.0419955577451 0.13910350753\n",
      "210 3 0.915713285081 0.230400653752 0.875291919664\n",
      "0.44814849169 0.0422879299952 0.13958448336\n",
      "220 3 0.9117441046 0.247776775295 0.872489490892\n",
      "0.474261550142 0.0423055074951 0.141028022169\n",
      "230 3 0.901704412795 0.257490677913 0.866884633349\n",
      "0.488891251123 0.0424889894978 0.142363955282\n",
      "240 3 0.915012841466 0.229941443526 0.874824848202\n",
      "0.523426288217 0.0421443692781 0.142290843193\n",
      "250 3 0.914312397852 0.233028724978 0.881363848669\n",
      "0.50608957325 0.0417754553363 0.140815890426\n",
      "260 3 0.9166472099 0.221285011336 0.879962634283\n",
      "0.536873025679 0.0416892298195 0.139940065649\n",
      "270 3 0.909409292552 0.245818914825 0.87669313405\n",
      "0.530875509207 0.0415672059042 0.139714241762\n",
      "280 3 0.901704412795 0.270482341981 0.861279775806\n",
      "0.505025838947 0.0416177498746 0.139201632318\n",
      "290 3 0.905440112071 0.270091913467 0.868752919197\n",
      "0.395177953759 0.0418951137745 0.139799030557\n",
      "300 3 0.907307961709 0.249818723233 0.871555347968\n",
      "0.432980507769 0.0418881065315 0.139650459211\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<TensorType(float64, matrix)>,\n",
       " <TensorType(float64, matrix)>,\n",
       " <TensorType(float64, matrix)>,\n",
       " <TensorType(float64, matrix)>]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if 1:  \n",
    "    i=0\n",
    "    while i<nb_step:\n",
    "        i+=1\n",
    "        for start, end in zip(range(0, len(trX), 10), range(10, len(trX), 10)):\n",
    "            cost = train(trX[start:end], trY[start:end])\n",
    "        #cost=train(trX,trY)\n",
    "        scoreTr=np.mean(np.argmax(trY, axis=1) == predict(trX))\n",
    "        \n",
    "        if i%10==0:#(nb_step/1)==0:\n",
    "            result=predictProb(trX)\n",
    "            argY=np.argmax(trY, axis=1)\n",
    "            logTr=loss(result,argY)\n",
    "            print i,nbLay,scoreTr,logTr, np.mean(np.argmax(teY, axis=1) == predict(teX))\n",
    "            print cost,0.0001*L1.eval(),0.001*L2.eval()\n",
    "\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params=[init_weights((size_input,nbNodes))]\n",
    "params.extend([init_weights((nbNodes,nbNodes)) for i in range(nbLay-1)])\n",
    "params.append(init_weights((nbNodes, size_output)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "L2_sqr = T.sum(L2_reg(np.array(params)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(2.9730365943150203)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L2_sqr.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params=[init_weights((size_input,nbNodes))]\n",
    "params.extend([init_weights((nbNodes,nbNodes)) for i in range(nbLay-1)])\n",
    "params.append(init_weights((nbNodes, size_output)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(2.9730365943150203)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L2_sqr.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(2.950055420821496)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L2_sqr = T.sum(L2_reg(np.array(params)))\n",
    "L2_sqr.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Elemwise{add,no_inplace}.0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.array(params)**2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    # symbolic Theano variable that represents the L1 regularization term\n",
    "    L1  = T.sum(abs(P))\n",
    "\n",
    "    # symbolic Theano variable that represents the squared L2 term\n",
    "    L2_sqr = T.sum(P ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "L1  = T.sum(abs(params[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sum{acc_dtype=float64}.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(74.1269312188022)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L1.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.0104779 , -0.01752108,  0.00152609, ..., -0.00392234,\n",
       "        -0.01745957,  0.00917721],\n",
       "       [-0.00469877,  0.00674319, -0.00766582, ..., -0.0167621 ,\n",
       "         0.00526074,  0.00495152],\n",
       "       [ 0.00108371,  0.00532334, -0.00675386, ...,  0.00297124,\n",
       "        -0.00271686, -0.00603125],\n",
       "       ..., \n",
       "       [ 0.01752274, -0.00239432,  0.0007575 , ...,  0.0155845 ,\n",
       "         0.01754397, -0.00494991],\n",
       "       [ 0.01123058, -0.0161085 , -0.00366557, ..., -0.0106872 ,\n",
       "        -0.00701879,  0.00298605],\n",
       "       [-0.00663227,  0.02798805, -0.02102916, ...,  0.00085213,\n",
       "         0.00667791,  0.00051049]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params[0].eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
